{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 3\n",
    "## Сравнение интересов аудитории телеканалов НТВ и Дождь с помощью тематического моделирования LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача:\n",
    "Сравнить интересы аудитории телеканолов НТВ и Дождь с помощью методов тематического моделирования\n",
    "1. Получить данные по аудитории из социальной сети ВК\n",
    "2. Зарегистрировать приложение, получить app_id, access_token\n",
    "3. Скачать данные по пользователям в каждой из групп (id групп ВК даны ниже, tvrain_id, ntv_id)\n",
    "4. Взять небольшую выборку из каждой совокупности телезрителей(около 1000-2000 человек, т.к. 300k-400k слишком много), с которыми работать дальше\n",
    "5. Обучить LDA модель на их подписках\n",
    "6. По группам, на которые подписаны эти люди, полуичть ключевые слова групп, на которые они подписаны\n",
    "7. Получить распределение интересов людей для каждой совокупности, сравнить на графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import sys  \n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для использования VK API необходимо создать приложение в VK\n",
    "\n",
    "1. Создать приложение по адресу https://vk.com/apps?act=manage (кнопка \"создать приложение\")\n",
    "2. При создании указать название, описание (можно любые), категория  - прочее. Тип - standalone приложение\n",
    "3. В настройках получить **app_id**. App_id потребуется для получения access token\n",
    "4. Авторизовать пользователя (получить access token) можно по адресу: https://vk.com/dev/first_guide, в правилах нас интересует пункт 3 **Авторизация пользователя**\n",
    "5. После того, как ознакомитесь с авторизацией пользователя, скопируйте в адресную строку такой запрос https://oauth.vk.com/authorize?client_id=5490057&display=page&redirect_uri=https://oauth.vk.com/blank.html&scope=friends&response_type=token&v=5.52, где число **5490057** замените на число, которое получите для вашего **app_id**\n",
    "6. Нажмите Enter. Откроется окно с запросом прав. В нем отображаются название приложения, иконки прав доступа, и Ваши имя с фамилией. Нажмите «Разрешить». Вы попадете на новую страницу с предупреждением о том, что токен нельзя копировать и передавать третьим лицам. В адресной строке будет URL https://oauth.vk.com/blank.html, а после # Вы увидите дополнительные параметры — access_token, expires_in и user_id. Токен может выглядеть, например, так: 51eff86578a3bbbcb5c7043a122a69fd04dca057ac821dd7afd7c2d8e35b60172d45a26599c08034cc40a\n",
    "7. Токен — это Ваш ключ доступа. При выполнении определенных условий человек, получивший Ваш токен, может нанести существенный ущерб Вашим данным и данным других людей. Поэтому очень важно не передавать свой токен третьим лицам\n",
    "8. Поле expires_in содержит время жизни токена в секундах. 86400 секунд — это ровно сутки. Через сутки полученный токен перестанет действовать, для продолжения работы нужно будет получить новый по такому же алгоритму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends_id = [68823,151290,246416,305724,320286,367685,474271,522873,736788,762309,824052,1030822,1075395,1085768,1104474,1151233,1170072,1238373,1306051,1371801,1375684,1576666,1782883,1844792,1846837,1847303,1939002,2036121,2049617,2087710,2103416,2107379,2158632,2159159,2201584,2319040,2321907,2395424,2434565,2440442,2572995,2668434,2789365,2813461,2907433,2949313,3029581,3167212,3172316,3182182,3189271,3202090,3370675,3372463,3393827,3436903,3451823,3478493,3488808,3507780,3521999,3578786,3592065,3649511,3677829,3701500,3732413,3813344,3914481,3917968,4022750,4049112,4185073,4264130,4305795,4342781,4388920,4418205,4509739,4540570,4548412,4585238,4606458,4689193,4773967,4918675,5068391,5087544,5092304,5157377,5242490,5254574,5317876,5346267,5357115,5374031,5525990,5547558,5823353,5873204,5875120,5875752,6087475,6161163,6312331,6531042,6596537,6662228,6716728,6733907,6783579,6809842,6882574,6934456,7063221,7065186,7162573,7344477,7439957,7597889,7675892,7684560,7775366,7814085,8040582,8175202,8259066,8362163,8463285,8507731,8575201,8615373,8795503,8805919,8909448,9098591,9191714,9602713,9683809,9802093,9946771,9961957,10073629,10379612,10724082,11073519,11328064,11502816,11858095,12258635,12801678,12927659,13600528,14646840,14758146,14766629,15039578,15359703,16744883,16890092,16924346,18077877,20336737,20516971,20532251,20836435,21247597,21627383,22062669,26540628,29464280,29765662,30236558,36004896,40526728,41480721,43900917,45465984,46878659,49525645,52470395,55593130,61146504,67034469,67117505,68209171,72464068,80675090,85013896,87157453,88218060,96681965,112440283,137829133,140086572,169900461,173380070,179943843,181073225,195917382,209512614,212681513,218384077,219789613,245457443,248123454,320526109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your own app id and respective tokens\n",
    "\n",
    "# скопируйте сюда ваши app_id и access_token, полученные по методу, описанному выше\n",
    "app_id = 6894772\n",
    "access_token = '0803d6ca735d7e82f2d58c1aaff755d1db3522eef69225f89c11748f9d29455985ad3e874971abf3c091d'\n",
    "\n",
    "# id групп ВК Дождя и НТВ\n",
    "tvrain_id = 17568841\n",
    "ntv_id = 28658784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ольга Монахова\n"
     ]
    }
   ],
   "source": [
    "# проверка работы API и авторизации пользователя. Если возникает ошибка, то, возможно, access token необходимо обновить\n",
    "check_id = 3559156\n",
    "\n",
    "my_id = 3559156\n",
    "\n",
    "# api call and test\n",
    "def vk_get_response(method, parameters, token):\n",
    "    url = 'https://api.vk.com/method/' + method + '?' + parameters + '&access_token=' + token\n",
    "#     print url\n",
    "    return(requests.get(url).json())\n",
    "\n",
    "answer = vk_get_response(\n",
    "    'users.get', 'user_ids={0}&v=4.9&lang=ru'.format(check_id), access_token\n",
    ")['response']\n",
    "print(answer[0]['first_name'], answer[0]['last_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получение подписчиков телеканалов НТВ и Дождь в VK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим объекты, которые содержат всю информацию о подпиичиках соответствующих групп (указанных в domains) и сохраним их на диск. Получим в итоге два файла - **ntv_subs** и **tvrain_subs** в формате **.pkl** - питоновский формат хранения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset:  0\n",
      "Offset:  1000\n",
      "Offset:  2000\n",
      "Offset:  3000\n",
      "Offset:  4000\n",
      "Offset:  5000\n",
      "Offset:  6000\n",
      "Offset:  7000\n",
      "Offset:  8000\n",
      "Offset:  9000\n",
      "Offset:  10000\n",
      "Offset:  11000\n",
      "Offset:  12000\n",
      "Offset:  13000\n",
      "Offset:  14000\n",
      "Offset:  15000\n",
      "Offset:  16000\n",
      "Offset:  17000\n",
      "Offset:  18000\n",
      "Offset:  19000\n",
      "Offset:  20000\n",
      "Offset:  21000\n",
      "Offset:  22000\n",
      "Offset:  23000\n",
      "Offset:  24000\n",
      "Offset:  25000\n",
      "Offset:  26000\n",
      "Offset:  27000\n",
      "Offset:  28000\n",
      "Offset:  29000\n",
      "Offset:  30000\n",
      "Offset:  31000\n",
      "Offset:  32000\n",
      "Offset:  33000\n",
      "Offset:  34000\n",
      "Offset:  35000\n",
      "Offset:  36000\n",
      "Offset:  37000\n",
      "Offset:  38000\n",
      "Offset:  39000\n",
      "Offset:  40000\n",
      "Offset:  41000\n",
      "Offset:  42000\n",
      "Offset:  43000\n",
      "Offset:  44000\n",
      "Offset:  45000\n",
      "Offset:  46000\n",
      "Offset:  47000\n",
      "Offset:  48000\n",
      "Offset:  49000\n",
      "Offset:  50000\n",
      "Offset:  51000\n",
      "Offset:  52000\n",
      "Offset:  53000\n",
      "Offset:  54000\n",
      "Offset:  55000\n",
      "Offset:  56000\n",
      "Offset:  57000\n",
      "Offset:  58000\n",
      "Offset:  59000\n",
      "Offset:  60000\n",
      "Offset:  61000\n",
      "Offset:  62000\n",
      "Offset:  63000\n",
      "Offset:  64000\n",
      "Offset:  65000\n",
      "Offset:  66000\n",
      "Offset:  67000\n",
      "Offset:  68000\n",
      "Offset:  69000\n",
      "Offset:  70000\n",
      "Offset:  71000\n",
      "Offset:  72000\n",
      "Offset:  73000\n",
      "Offset:  74000\n",
      "Offset:  75000\n",
      "Offset:  76000\n",
      "Offset:  77000\n",
      "Offset:  78000\n",
      "Offset:  79000\n",
      "Offset:  80000\n",
      "Offset:  81000\n",
      "Offset:  82000\n",
      "Offset:  83000\n",
      "Offset:  84000\n",
      "Offset:  85000\n",
      "Offset:  86000\n",
      "Offset:  87000\n",
      "Offset:  88000\n",
      "Offset:  89000\n",
      "Offset:  90000\n",
      "Offset:  91000\n",
      "Offset:  92000\n",
      "Offset:  93000\n",
      "Offset:  94000\n",
      "Offset:  95000\n",
      "Offset:  96000\n",
      "Offset:  97000\n",
      "Offset:  98000\n",
      "Offset:  99000\n",
      "Offset:  100000\n",
      "Offset:  101000\n",
      "Offset:  102000\n",
      "Offset:  103000\n",
      "Offset:  104000\n",
      "Offset:  105000\n",
      "Offset:  106000\n",
      "Offset:  107000\n",
      "Offset:  108000\n",
      "Offset:  109000\n",
      "Offset:  110000\n",
      "Offset:  111000\n",
      "Offset:  112000\n",
      "Offset:  113000\n",
      "Offset:  114000\n",
      "Offset:  115000\n",
      "Offset:  116000\n",
      "Offset:  117000\n",
      "Offset:  118000\n",
      "Offset:  119000\n",
      "Offset:  120000\n",
      "Offset:  121000\n",
      "Offset:  122000\n",
      "Offset:  123000\n",
      "Offset:  124000\n",
      "Offset:  125000\n",
      "Offset:  126000\n",
      "Offset:  127000\n",
      "Offset:  128000\n",
      "Offset:  129000\n",
      "Offset:  130000\n",
      "Offset:  131000\n",
      "Offset:  132000\n",
      "Offset:  133000\n",
      "Offset:  134000\n",
      "Offset:  135000\n",
      "Offset:  136000\n",
      "Offset:  137000\n",
      "Offset:  138000\n",
      "Offset:  139000\n",
      "Offset:  140000\n",
      "Offset:  141000\n",
      "Offset:  142000\n",
      "Offset:  143000\n",
      "Offset:  144000\n",
      "Offset:  145000\n",
      "Offset:  146000\n",
      "Offset:  147000\n",
      "Offset:  148000\n",
      "Offset:  149000\n",
      "Offset:  150000\n",
      "Offset:  151000\n",
      "Offset:  152000\n",
      "Offset:  153000\n",
      "Offset:  154000\n",
      "Offset:  155000\n",
      "Offset:  156000\n",
      "Offset:  157000\n",
      "Offset:  158000\n",
      "Offset:  159000\n",
      "Offset:  160000\n",
      "Offset:  161000\n",
      "Offset:  162000\n",
      "Offset:  163000\n",
      "Offset:  164000\n",
      "Offset:  165000\n",
      "Offset:  166000\n",
      "Offset:  167000\n",
      "Offset:  168000\n",
      "Offset:  169000\n",
      "Offset:  170000\n",
      "Offset:  171000\n",
      "Offset:  172000\n",
      "Offset:  173000\n",
      "Offset:  174000\n",
      "Offset:  175000\n",
      "Offset:  176000\n",
      "Offset:  177000\n",
      "Offset:  178000\n",
      "Offset:  179000\n",
      "Offset:  180000\n",
      "Offset:  181000\n",
      "Offset:  182000\n",
      "Offset:  183000\n",
      "Offset:  184000\n",
      "Offset:  185000\n",
      "Offset:  186000\n",
      "Offset:  187000\n",
      "Offset:  188000\n",
      "Offset:  189000\n",
      "Offset:  190000\n",
      "Offset:  191000\n",
      "Offset:  192000\n",
      "Offset:  193000\n",
      "Offset:  194000\n",
      "Offset:  195000\n",
      "Offset:  196000\n",
      "Offset:  197000\n",
      "Offset:  198000\n",
      "Offset:  199000\n",
      "Offset:  200000\n",
      "Offset:  201000\n",
      "Offset:  202000\n",
      "Offset:  203000\n",
      "Offset:  204000\n",
      "Offset:  205000\n",
      "Offset:  206000\n",
      "Offset:  207000\n",
      "Offset:  208000\n",
      "Offset:  209000\n",
      "Offset:  210000\n",
      "Offset:  211000\n",
      "Offset:  212000\n",
      "Offset:  213000\n",
      "Offset:  214000\n",
      "Offset:  215000\n",
      "Offset:  216000\n",
      "Offset:  217000\n",
      "Offset:  218000\n",
      "Offset:  219000\n",
      "Offset:  220000\n",
      "Offset:  221000\n",
      "Offset:  222000\n",
      "Offset:  223000\n",
      "Offset:  224000\n",
      "Offset:  225000\n",
      "Offset:  226000\n",
      "Offset:  227000\n",
      "Offset:  228000\n",
      "Offset:  229000\n",
      "Offset:  230000\n",
      "Offset:  231000\n",
      "Offset:  232000\n",
      "Offset:  233000\n",
      "Offset:  234000\n",
      "Offset:  235000\n",
      "Offset:  236000\n",
      "Offset:  237000\n",
      "Offset:  238000\n",
      "Offset:  239000\n",
      "Offset:  240000\n",
      "Offset:  241000\n",
      "Offset:  242000\n",
      "Offset:  243000\n",
      "Offset:  244000\n",
      "Offset:  245000\n",
      "Offset:  246000\n",
      "Offset:  247000\n",
      "Offset:  248000\n",
      "Offset:  249000\n",
      "Offset:  250000\n",
      "Offset:  251000\n",
      "Offset:  252000\n",
      "Offset:  253000\n",
      "Offset:  254000\n",
      "Offset:  255000\n",
      "Offset:  256000\n",
      "Offset:  257000\n",
      "Offset:  258000\n",
      "Offset:  259000\n",
      "Offset:  260000\n",
      "Offset:  261000\n",
      "Offset:  262000\n",
      "Offset:  263000\n",
      "Offset:  264000\n",
      "Offset:  265000\n",
      "Offset:  266000\n",
      "Offset:  267000\n",
      "Offset:  268000\n",
      "Offset:  269000\n",
      "Offset:  270000\n",
      "Offset:  271000\n",
      "Offset:  272000\n",
      "Offset:  273000\n",
      "Offset:  274000\n",
      "Offset:  275000\n",
      "Offset:  276000\n",
      "Offset:  277000\n",
      "Offset:  278000\n",
      "Offset:  279000\n",
      "Offset:  280000\n",
      "Offset:  281000\n",
      "Offset:  282000\n",
      "Offset:  283000\n",
      "Offset:  284000\n",
      "Offset:  285000\n",
      "Offset:  286000\n",
      "Offset:  287000\n",
      "Offset:  288000\n",
      "Offset:  289000\n",
      "Offset:  290000\n",
      "Offset:  291000\n",
      "Offset:  292000\n",
      "Offset:  293000\n",
      "Offset:  294000\n",
      "Offset:  295000\n",
      "Offset:  296000\n",
      "Offset:  297000\n",
      "Offset:  298000\n",
      "Offset:  299000\n",
      "Offset:  300000\n",
      "Offset:  301000\n",
      "Offset:  302000\n",
      "Offset:  303000\n",
      "Offset:  304000\n",
      "Offset:  305000\n",
      "Offset:  306000\n",
      "Offset:  307000\n",
      "Offset:  308000\n",
      "Offset:  309000\n",
      "Offset:  310000\n",
      "Offset:  311000\n",
      "Offset:  312000\n",
      "Offset:  313000\n",
      "Offset:  314000\n",
      "Offset:  315000\n",
      "Offset:  316000\n",
      "Offset:  317000\n",
      "Offset:  318000\n",
      "Offset:  319000\n",
      "Offset:  320000\n",
      "Offset:  321000\n",
      "Offset:  322000\n",
      "Offset:  323000\n",
      "Offset:  324000\n",
      "Offset:  325000\n",
      "Offset:  326000\n",
      "Offset:  327000\n",
      "Offset:  328000\n",
      "Offset:  329000\n",
      "Offset:  330000\n",
      "Offset:  331000\n",
      "Offset:  332000\n",
      "Offset:  333000\n",
      "Offset:  334000\n",
      "Offset:  335000\n",
      "Offset:  336000\n",
      "Offset:  337000\n",
      "Offset:  338000\n",
      "Offset:  339000\n",
      "Offset:  340000\n",
      "Offset:  341000\n",
      "Offset:  342000\n",
      "Offset:  343000\n",
      "Offset:  344000\n",
      "Offset:  345000\n",
      "Offset:  346000\n",
      "Offset:  347000\n",
      "Offset:  348000\n",
      "Offset:  349000\n",
      "Offset:  350000\n",
      "Offset:  351000\n",
      "Offset:  352000\n",
      "Offset:  353000\n",
      "Offset:  354000\n",
      "Offset:  355000\n",
      "Offset:  356000\n",
      "Offset:  357000\n",
      "Offset:  358000\n",
      "Offset:  359000\n",
      "Offset:  360000\n",
      "Offset:  361000\n",
      "Offset:  362000\n",
      "Offset:  363000\n",
      "Offset:  364000\n",
      "Offset:  365000\n",
      "Offset:  366000\n",
      "Offset:  367000\n",
      "Offset:  368000\n",
      "Offset:  369000\n",
      "Offset:  370000\n",
      "Offset:  0\n",
      "Offset:  1000\n",
      "Offset:  2000\n",
      "Offset:  3000\n",
      "Offset:  4000\n",
      "Offset:  5000\n",
      "Offset:  6000\n",
      "Offset:  7000\n",
      "Offset:  8000\n",
      "Offset:  9000\n",
      "Offset:  10000\n",
      "Offset:  11000\n",
      "Offset:  12000\n",
      "Offset:  13000\n",
      "Offset:  14000\n",
      "Offset:  15000\n",
      "Offset:  16000\n",
      "Offset:  17000\n",
      "Offset:  18000\n",
      "Offset:  19000\n",
      "Offset:  20000\n",
      "Offset:  21000\n",
      "Offset:  22000\n",
      "Offset:  23000\n",
      "Offset:  24000\n",
      "Offset:  25000\n",
      "Offset:  26000\n",
      "Offset:  27000\n",
      "Offset:  28000\n",
      "Offset:  29000\n",
      "Offset:  30000\n",
      "Offset:  31000\n",
      "Offset:  32000\n",
      "Offset:  33000\n",
      "Offset:  34000\n",
      "Offset:  35000\n",
      "Offset:  36000\n",
      "Offset:  37000\n",
      "Offset:  38000\n",
      "Offset:  39000\n",
      "Offset:  40000\n",
      "Offset:  41000\n",
      "Offset:  42000\n",
      "Offset:  43000\n",
      "Offset:  44000\n",
      "Offset:  45000\n",
      "Offset:  46000\n",
      "Offset:  47000\n",
      "Offset:  48000\n",
      "Offset:  49000\n",
      "Offset:  50000\n",
      "Offset:  51000\n",
      "Offset:  52000\n",
      "Offset:  53000\n",
      "Offset:  54000\n",
      "Offset:  55000\n",
      "Offset:  56000\n",
      "Offset:  57000\n",
      "Offset:  58000\n",
      "Offset:  59000\n",
      "Offset:  60000\n",
      "Offset:  61000\n",
      "Offset:  62000\n",
      "Offset:  63000\n",
      "Offset:  64000\n",
      "Offset:  65000\n",
      "Offset:  66000\n",
      "Offset:  67000\n",
      "Offset:  68000\n",
      "Offset:  69000\n",
      "Offset:  70000\n",
      "Offset:  71000\n",
      "Offset:  72000\n",
      "Offset:  73000\n",
      "Offset:  74000\n",
      "Offset:  75000\n",
      "Offset:  76000\n",
      "Offset:  77000\n",
      "Offset:  78000\n",
      "Offset:  79000\n",
      "Offset:  80000\n",
      "Offset:  81000\n",
      "Offset:  82000\n",
      "Offset:  83000\n",
      "Offset:  84000\n",
      "Offset:  85000\n",
      "Offset:  86000\n",
      "Offset:  87000\n",
      "Offset:  88000\n",
      "Offset:  89000\n",
      "Offset:  90000\n",
      "Offset:  91000\n",
      "Offset:  92000\n",
      "Offset:  93000\n",
      "Offset:  94000\n",
      "Offset:  95000\n",
      "Offset:  96000\n",
      "Offset:  97000\n",
      "Offset:  98000\n",
      "Offset:  99000\n",
      "Offset:  100000\n",
      "Offset:  101000\n",
      "Offset:  102000\n",
      "Offset:  103000\n",
      "Offset:  104000\n",
      "Offset:  105000\n",
      "Offset:  106000\n",
      "Offset:  107000\n",
      "Offset:  108000\n",
      "Offset:  109000\n",
      "Offset:  110000\n",
      "Offset:  111000\n",
      "Offset:  112000\n",
      "Offset:  113000\n",
      "Offset:  114000\n",
      "Offset:  115000\n",
      "Offset:  116000\n",
      "Offset:  117000\n",
      "Offset:  118000\n",
      "Offset:  119000\n",
      "Offset:  120000\n",
      "Offset:  121000\n",
      "Offset:  122000\n",
      "Offset:  123000\n",
      "Offset:  124000\n",
      "Offset:  125000\n",
      "Offset:  126000\n",
      "Offset:  127000\n",
      "Offset:  128000\n",
      "Offset:  129000\n",
      "Offset:  130000\n",
      "Offset:  131000\n",
      "Offset:  132000\n",
      "Offset:  133000\n",
      "Offset:  134000\n",
      "Offset:  135000\n",
      "Offset:  136000\n",
      "Offset:  137000\n",
      "Offset:  138000\n",
      "Offset:  139000\n",
      "Offset:  140000\n",
      "Offset:  141000\n",
      "Offset:  142000\n",
      "Offset:  143000\n",
      "Offset:  144000\n",
      "Offset:  145000\n",
      "Offset:  146000\n",
      "Offset:  147000\n",
      "Offset:  148000\n",
      "Offset:  149000\n",
      "Offset:  150000\n",
      "Offset:  151000\n",
      "Offset:  152000\n",
      "Offset:  153000\n",
      "Offset:  154000\n",
      "Offset:  155000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset:  156000\n",
      "Offset:  157000\n",
      "Offset:  158000\n",
      "Offset:  159000\n",
      "Offset:  160000\n",
      "Offset:  161000\n",
      "Offset:  162000\n",
      "Offset:  163000\n",
      "Offset:  164000\n",
      "Offset:  165000\n",
      "Offset:  166000\n",
      "Offset:  167000\n",
      "Offset:  168000\n",
      "Offset:  169000\n",
      "Offset:  170000\n",
      "Offset:  171000\n",
      "Offset:  172000\n",
      "Offset:  173000\n",
      "Offset:  174000\n",
      "Offset:  175000\n",
      "Offset:  176000\n",
      "Offset:  177000\n",
      "Offset:  178000\n",
      "Offset:  179000\n",
      "Offset:  180000\n",
      "Offset:  181000\n",
      "Offset:  182000\n",
      "Offset:  183000\n",
      "Offset:  184000\n",
      "Offset:  185000\n",
      "Offset:  186000\n",
      "Offset:  187000\n",
      "Offset:  188000\n",
      "Offset:  189000\n",
      "Offset:  190000\n",
      "Offset:  191000\n",
      "Offset:  192000\n",
      "Offset:  193000\n",
      "Offset:  194000\n",
      "Offset:  195000\n",
      "Offset:  196000\n",
      "Offset:  197000\n",
      "Offset:  198000\n",
      "Offset:  199000\n",
      "Offset:  200000\n",
      "Offset:  201000\n",
      "Offset:  202000\n",
      "Offset:  203000\n",
      "Offset:  204000\n",
      "Offset:  205000\n",
      "Offset:  206000\n",
      "Offset:  207000\n",
      "Offset:  208000\n",
      "Offset:  209000\n",
      "Offset:  210000\n",
      "Offset:  211000\n",
      "Offset:  212000\n",
      "Offset:  213000\n",
      "Offset:  214000\n",
      "Offset:  215000\n",
      "Offset:  216000\n",
      "Offset:  217000\n",
      "Offset:  218000\n",
      "Offset:  219000\n",
      "Offset:  220000\n",
      "Offset:  221000\n",
      "Offset:  222000\n",
      "Offset:  223000\n",
      "Offset:  224000\n",
      "Offset:  225000\n",
      "Offset:  226000\n",
      "Offset:  227000\n",
      "Offset:  228000\n",
      "Offset:  229000\n",
      "Offset:  230000\n",
      "Offset:  231000\n",
      "Offset:  232000\n",
      "Offset:  233000\n",
      "Offset:  234000\n",
      "Offset:  235000\n",
      "Offset:  236000\n",
      "Offset:  237000\n",
      "Offset:  238000\n",
      "Offset:  239000\n",
      "Offset:  240000\n",
      "Offset:  241000\n",
      "Offset:  242000\n",
      "Offset:  243000\n",
      "Offset:  244000\n",
      "Offset:  245000\n",
      "Offset:  246000\n",
      "Offset:  247000\n",
      "Offset:  248000\n",
      "Offset:  249000\n",
      "Offset:  250000\n",
      "Offset:  251000\n",
      "Offset:  252000\n",
      "Offset:  253000\n",
      "Offset:  254000\n",
      "Offset:  255000\n",
      "Offset:  256000\n",
      "Offset:  257000\n",
      "Offset:  258000\n",
      "Offset:  259000\n",
      "Offset:  260000\n",
      "Offset:  261000\n",
      "Offset:  262000\n",
      "Offset:  263000\n",
      "Offset:  264000\n",
      "Offset:  265000\n",
      "Offset:  266000\n",
      "Offset:  267000\n",
      "Offset:  268000\n",
      "Offset:  269000\n",
      "Offset:  270000\n",
      "Offset:  271000\n",
      "Offset:  272000\n",
      "Offset:  273000\n",
      "Offset:  274000\n",
      "Offset:  275000\n",
      "Offset:  276000\n",
      "Offset:  277000\n",
      "Offset:  278000\n",
      "Offset:  279000\n",
      "Offset:  280000\n",
      "Offset:  281000\n",
      "Offset:  282000\n",
      "Offset:  283000\n",
      "Offset:  284000\n",
      "Offset:  285000\n",
      "Offset:  286000\n",
      "Offset:  287000\n",
      "Offset:  288000\n",
      "Offset:  289000\n",
      "Offset:  290000\n",
      "Offset:  291000\n",
      "Offset:  292000\n",
      "Offset:  293000\n",
      "Offset:  294000\n",
      "Offset:  295000\n",
      "Offset:  296000\n",
      "Offset:  297000\n",
      "Offset:  298000\n",
      "Offset:  299000\n",
      "Offset:  300000\n",
      "Offset:  301000\n",
      "Offset:  302000\n",
      "Offset:  303000\n",
      "Offset:  304000\n",
      "Offset:  305000\n",
      "Offset:  306000\n",
      "Offset:  307000\n",
      "Offset:  308000\n",
      "Offset:  309000\n",
      "Offset:  310000\n",
      "Offset:  311000\n",
      "Offset:  312000\n",
      "Offset:  313000\n",
      "Offset:  314000\n",
      "Offset:  315000\n",
      "Offset:  316000\n",
      "Offset:  317000\n",
      "Offset:  318000\n",
      "Offset:  319000\n",
      "Offset:  320000\n",
      "Offset:  321000\n",
      "Offset:  322000\n",
      "Offset:  323000\n",
      "Offset:  324000\n",
      "Offset:  325000\n",
      "Offset:  326000\n",
      "Offset:  327000\n",
      "Offset:  328000\n",
      "Offset:  329000\n",
      "Offset:  330000\n",
      "Offset:  331000\n",
      "Offset:  332000\n",
      "Offset:  333000\n",
      "Offset:  334000\n",
      "Offset:  335000\n",
      "Offset:  336000\n",
      "Offset:  337000\n",
      "Offset:  338000\n",
      "Offset:  339000\n",
      "Offset:  340000\n",
      "Offset:  341000\n",
      "Offset:  342000\n",
      "Offset:  343000\n",
      "Offset:  344000\n",
      "Offset:  345000\n",
      "Offset:  346000\n",
      "Offset:  347000\n",
      "Offset:  348000\n",
      "Offset:  349000\n",
      "Offset:  350000\n",
      "Offset:  351000\n",
      "Offset:  352000\n",
      "Offset:  353000\n",
      "Offset:  354000\n",
      "Offset:  355000\n",
      "Offset:  356000\n",
      "Offset:  357000\n",
      "Offset:  358000\n",
      "Offset:  359000\n",
      "Offset:  360000\n",
      "Offset:  361000\n",
      "Offset:  362000\n",
      "Offset:  363000\n",
      "Offset:  364000\n",
      "Offset:  365000\n",
      "Offset:  366000\n",
      "Offset:  367000\n",
      "Offset:  368000\n",
      "Offset:  369000\n",
      "Offset:  370000\n",
      "Offset:  371000\n",
      "Offset:  372000\n",
      "Offset:  373000\n",
      "Offset:  374000\n",
      "Offset:  375000\n",
      "Offset:  376000\n",
      "Offset:  377000\n",
      "Offset:  378000\n",
      "Offset:  379000\n",
      "Offset:  380000\n",
      "Offset:  381000\n",
      "Offset:  382000\n",
      "Offset:  383000\n",
      "Offset:  384000\n",
      "Offset:  385000\n",
      "Offset:  386000\n",
      "Offset:  387000\n",
      "Offset:  388000\n",
      "Offset:  389000\n",
      "Offset:  390000\n",
      "Offset:  391000\n",
      "Offset:  392000\n",
      "Offset:  393000\n",
      "Offset:  394000\n",
      "Offset:  395000\n",
      "Offset:  396000\n",
      "Offset:  397000\n",
      "Offset:  398000\n",
      "Offset:  399000\n",
      "Offset:  400000\n",
      "Offset:  401000\n",
      "Offset:  402000\n",
      "Offset:  403000\n",
      "Offset:  404000\n",
      "Offset:  405000\n",
      "Offset:  406000\n",
      "Offset:  407000\n",
      "Offset:  408000\n",
      "Offset:  409000\n",
      "Offset:  410000\n",
      "Offset:  411000\n",
      "Offset:  412000\n",
      "Offset:  413000\n",
      "Offset:  414000\n",
      "Offset:  415000\n",
      "Offset:  416000\n",
      "Offset:  417000\n",
      "Offset:  418000\n",
      "Offset:  419000\n",
      "Offset:  420000\n",
      "Offset:  421000\n",
      "Offset:  422000\n",
      "Offset:  423000\n",
      "Offset:  424000\n",
      "Offset:  425000\n",
      "Offset:  426000\n",
      "Offset:  427000\n",
      "Offset:  428000\n",
      "Offset:  429000\n",
      "Offset:  430000\n",
      "Offset:  431000\n",
      "Offset:  432000\n",
      "Offset:  433000\n",
      "Offset:  434000\n",
      "Offset:  435000\n",
      "Offset:  436000\n",
      "Offset:  437000\n",
      "Offset:  438000\n",
      "Offset:  439000\n",
      "Offset:  440000\n",
      "Offset:  441000\n",
      "Offset:  442000\n",
      "Offset:  443000\n",
      "Offset:  444000\n"
     ]
    }
   ],
   "source": [
    "domains = ['ntv', 'tvrain']\n",
    "\n",
    "\n",
    "for group_domain in domains:\n",
    "    offset = 0\n",
    "    group_id = group_domain\n",
    "    fields = \"\"\"sex,bdate,city,country,home_town,lists,domain,has_mobile,\n",
    "    contacts,connections,education,universities,followers_count,occupation,last_seen,relation\"\"\"\n",
    "    first_sample = vk_get_response(\n",
    "        'groups.getMembers', 'group_id={0}&offset={1}&fields={2}&v=4.9&lang=ru'.format(\n",
    "            group_id, offset, fields\n",
    "        ), token=access_token\n",
    "    )\n",
    "    community_count = first_sample['response']['count']\n",
    "    community_members = []\n",
    "    for i in range(community_count // 1000 + 1):\n",
    "        offset = i * 1000\n",
    "        try:\n",
    "            answer = vk_get_response(\n",
    "                'groups.getMembers', 'group_id={0}&offset={1}&fields={2}&v=4.9&lang=ru'.format(\n",
    "                    group_id, offset, fields), token=access_token\n",
    "            )\n",
    "            print(\"Offset: \", offset)\n",
    "        except:\n",
    "            print(\"Offset: \", offset, \" Error\")\n",
    "        community_members += answer['response']['users']\n",
    "    save_obj(community_members, '{}_subs'.format(group_domain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_ntv = load_obj('ntv_subs')\n",
    "community_tvrain = load_obj('tvrain_subs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_ntv_df = pd.DataFrame(community_ntv)\n",
    "community_tvrain_df = pd.DataFrame(community_tvrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала получим всех уникальных подписчиков НТВ и Дождя с помощью unique. Далее с помощью numpy.random необходимо выбрать небольшой sample (например, по 1000 из каждой группы) таких людей и объединить их вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntv_uids = community_ntv_df.uid.unique().tolist()\n",
    "tvrain_uids = community_tvrain_df.uid.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntv_uids_sample = np.random.choice(ntv_uids, 1001)\n",
    "tvrain_uids_sample = np.random.choice(tvrain_uids, 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получить общий список людей из двух выборок НТВ и Дождя, всего должно быть в итоге около 2000 человек\n",
    "uids = list(set(np.concatenate((ntv_uids_sample,tvrain_uids_sample))))\n",
    "len(uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 profiles done\n",
      "100 profiles done\n",
      "200 profiles done\n",
      "300 profiles done\n",
      "400 profiles done\n",
      "500 profiles done\n",
      "600 profiles done\n",
      "700 profiles done\n",
      "800 profiles done\n",
      "900 profiles done\n"
     ]
    }
   ],
   "source": [
    "# получить подписки этих пользователей\n",
    "print_counter = 0\n",
    "final_data = []\n",
    "\n",
    "for uid in uids[:1000]:\n",
    "    try:\n",
    "        user_subs = vk_get_response(\n",
    "            'users.getSubscriptions', 'user_id={0}&v=4.9&lang=ru'.format(int(uid)), access_token\n",
    "        )\n",
    "        time.sleep(0.3)\n",
    "        final_data.append(user_subs)\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "    if print_counter % 100 == 0:\n",
    "        print(\"{0} profiles done\".format(print_counter))\n",
    "    print_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 users\n",
      "Processed 100 users\n",
      "Processed 100 users\n",
      "Processed 100 users\n",
      "Processed 200 users\n",
      "Processed 300 users\n",
      "Processed 300 users\n",
      "Processed 300 users\n",
      "Processed 400 users\n",
      "Processed 400 users\n",
      "Processed 500 users\n",
      "Processed 600 users\n",
      "Processed 700 users\n",
      "Processed 700 users\n"
     ]
    }
   ],
   "source": [
    "subs_list = []\n",
    "groups_freq_dict = {}\n",
    "top_n = 5\n",
    "\n",
    "for record, uid in zip(final_data, uids):\n",
    "    try:\n",
    "        user_subs = record\n",
    "        if not user_subs.get('response'):\n",
    "            user_subs = vk_get_response(\n",
    "                'users.getSubscriptions', 'user_id={0}&v=4.9&lang=ru'.format(int(uid)), access_token\n",
    "            )\n",
    "        subs_pd = pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    'groups_count': user_subs['response']['groups'].get('count'),\n",
    "                    'groups_list': user_subs['response']['groups'].get('items'),\n",
    "                    'follows_count':user_subs['response']['users'].get('count'),\n",
    "                    'follows_list': user_subs['response']['users'].get('items'),\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for group_id in user_subs['response']['groups'].get('items')[:top_n]:\n",
    "            if groups_freq_dict.get(group_id):\n",
    "                groups_freq_dict[group_id] += 1\n",
    "            else:\n",
    "                groups_freq_dict[group_id] = 1\n",
    "\n",
    "        subs_pd['subs_count'] = subs_pd['groups_count'] + subs_pd['follows_count']\n",
    "        subs_list.append(subs_pd)\n",
    "    except:\n",
    "#         print(user_subs)\n",
    "        pass\n",
    "    if len(subs_list) % 100 == 0:\n",
    "        print(\"Processed {0} users\".format(len(subs_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самые популярные группы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17568841, 103),\n",
       " (28658784, 80),\n",
       " (68519692, 28),\n",
       " (29534144, 24),\n",
       " (15755094, 21)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(key, val) for key, val in groups_freq_dict.items()], key=lambda x: x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка постов со стен групп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 groups extracted\n",
      "200 groups extracted\n",
      "300 groups extracted\n",
      "400 groups extracted\n",
      "500 groups extracted\n",
      "600 groups extracted\n",
      "700 groups extracted\n",
      "800 groups extracted\n",
      "900 groups extracted\n",
      "1000 groups extracted\n",
      "Response error. Group id 130785484\n",
      "{'error': {'error_code': 15, 'error_msg': 'Access denied: this wall available only for community members', 'request_params': [{'key': 'oauth', 'value': '1'}, {'key': 'method', 'value': 'wall.get'}, {'key': 'owner_id', 'value': '-130785484'}, {'key': 'count', 'value': '100'}, {'key': 'fields', 'value': 'post_type,marked_as_ads'}, {'key': '', 'value': ''}, {'key': 'v', 'value': '4.9'}, {'key': 'lang', 'value': 'ru'}]}}\n",
      "1100 groups extracted\n",
      "1200 groups extracted\n",
      "1300 groups extracted\n",
      "1400 groups extracted\n",
      "1500 groups extracted\n",
      "1600 groups extracted\n",
      "1700 groups extracted\n",
      "1800 groups extracted\n",
      "1900 groups extracted\n",
      "2000 groups extracted\n",
      "2100 groups extracted\n",
      "2200 groups extracted\n",
      "2300 groups extracted\n",
      "2400 groups extracted\n"
     ]
    }
   ],
   "source": [
    "group_doc_dict = {}\n",
    "counter = 0\n",
    "groups_freq_dict_top5 = groups_freq_dict\n",
    "\n",
    "for group_id, freq in groups_freq_dict_top5.items():\n",
    "    counter += 1\n",
    "    try:\n",
    "        check = vk_get_response(\n",
    "            'wall.get',\n",
    "            'owner_id={0}&count=100&fields=post_type,marked_as_ads&&v=4.9&lang=ru'.format(int(group_id) * -1),\n",
    "            access_token\n",
    "        )\n",
    "        check = check['response']\n",
    "        group_doc = ''\n",
    "        if check[0] != 0:\n",
    "            for post in check[1:]:\n",
    "                if post.get('marked_as_ads') != 1:\n",
    "                    group_doc += post['text']\n",
    "        group_doc_dict[group_id] = group_doc\n",
    "    except:\n",
    "        print(\"Response error. Group id {0}\".format(group_id))\n",
    "        print(check)\n",
    "    if counter % 100 == 0:\n",
    "        print(\"{0} groups extracted\".format(counter))\n",
    "    time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранить сырые данные по постам групп на диск\n",
    "save_obj(group_doc_dict, 'group_doc_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 556kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4 (from pymorphy2)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.1MB 672kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /Users/olgamonahova/anaconda3/lib/python3.6/site-packages (from pymorphy2) (0.6.2)\n",
      "Collecting dawg-python>=0.7 (from pymorphy2)\n",
      "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
      "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/olgamonahova/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrs_to_delete = string.punctuation + u'»' + u'«' + u'—' + u'“' + u'„' + u'•' + u'#'\n",
    "translation_table = {ord(c): None for c in chrs_to_delete if c != u'-'}\n",
    "units = MorphAnalyzer.DEFAULT_UNITS\n",
    "morph = MorphAnalyzer(result_type=None, units=units)\n",
    "PortSt = PorterStemmer()\n",
    "stopw = set(\n",
    "    [w for w in stopwords.words(['russian', 'english'])]\n",
    "    + [u'это', u'году', u'года', u'также', u'етот',\n",
    "       u'которые', u'который', u'которая', u'поэтому',\n",
    "       u'весь', u'свой', u'мочь', u'eтот', u'например',\n",
    "       u'какой-то', u'кто-то', u'самый', u'очень', u'несколько',\n",
    "       u'источник', u'стать', u'время', u'пока', u'однако',\n",
    "       u'около', u'немного', u'кроме', u'гораздо', u'каждый',\n",
    "       u'первый', u'вполне', u'из-за', u'из-под',\n",
    "       u'второй', u'нужно', u'нужный', u'просто', u'большой',\n",
    "       u'хороший', u'хотеть', u'начать', u'должный', u'новый', u'день',\n",
    "       u'метр', u'получить', u'далее', u'именно', u'апрель',\n",
    "       u'сообщать', u'разный', u'говорить', u'делать',\n",
    "       u'появиться', u'2016',\n",
    "       u'2015', u'получить', u'иметь', u'составить', u'дать', u'читать',\n",
    "       u'ничто', u'достаточно', u'использовать',\n",
    "       u'принять', u'практически',\n",
    "       u'находиться', u'месяц', u'достаточно', u'что-то', u'часто',\n",
    "       u'хотеть', u'начаться', u'делать', u'событие', u'составлять',\n",
    "       u'остаться', u'заявить', u'сделать', u'дело',\n",
    "       u'примерно', u'попасть', u'хотя', u'лишь', u'первое',\n",
    "       u'больший', u'решить', u'число', u'идти', u'давать', u'вопрос',\n",
    "       u'сегодня', u'часть', u'высокий', u'главный', u'случай', u'место',\n",
    "       u'конец', u'работать', u'работа', u'слово', u'важный', u'сказать']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_start = 'http[s]?://'\n",
    "url_end = (\n",
    "    '(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    ")\n",
    "pattern = url_start + url_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка слов постов групп - трансформация в \"хороший\" вид. Нормализация и стэмминг, удаление стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 docs processed\n",
      "200 docs processed\n",
      "300 docs processed\n",
      "400 docs processed\n",
      "500 docs processed\n",
      "600 docs processed\n",
      "700 docs processed\n",
      "800 docs processed\n",
      "900 docs processed\n",
      "1000 docs processed\n",
      "1100 docs processed\n",
      "1200 docs processed\n",
      "1300 docs processed\n",
      "1400 docs processed\n",
      "1500 docs processed\n",
      "1600 docs processed\n",
      "1700 docs processed\n",
      "1800 docs processed\n",
      "1900 docs processed\n",
      "2000 docs processed\n",
      "2100 docs processed\n",
      "2200 docs processed\n",
      "2300 docs processed\n",
      "2400 docs processed\n"
     ]
    }
   ],
   "source": [
    "group_clean_doc_dict = {}\n",
    "counter = 0\n",
    "\n",
    "for group_id, doc in group_doc_dict.items():\n",
    "    soup = BeautifulSoup(doc, 'html.parser')\n",
    "    body = ' '.join(\n",
    "        [tag.string.replace('\\\\n', ' ').replace('\\\\r', ' ')\n",
    "         for tag in soup.descendants if tag.string]\n",
    "    )\n",
    "    body = re.sub('\\[.*?\\]','', body)\n",
    "    body = re.sub(pattern,'', body)\n",
    "    if body != '':\n",
    "        body_clean = body.translate(translation_table).lower().strip()\n",
    "        words = word_tokenize(body_clean)\n",
    "        tokens = []\n",
    "        # stemming and text normalization\n",
    "        for word in words:\n",
    "            if re.match('^[a-z0-9-]+$', word) is not None:\n",
    "                tokens.append(PortSt.stem(word))\n",
    "            elif word.count('-') > 1:\n",
    "                tokens.append(word)\n",
    "            else:\n",
    "                normal_forms = morph.normal_forms(word)\n",
    "                tokens.append(normal_forms[0] if normal_forms else word)\n",
    "        # remove stopwords and leave unique words only\n",
    "        tokens = filter(\n",
    "            lambda token: token not in stopw, sorted(set(tokens))\n",
    "        )\n",
    "\n",
    "        # remove all words with more than 3 chars\n",
    "        tokens = filter(lambda token: len(token) > 3, tokens)\n",
    "    else:\n",
    "        tokens = []\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(\"{0} docs processed\".format(counter))\n",
    "    group_clean_doc_dict[group_id] = tokens\n",
    "\n",
    "group_clean_doc_dict = {key: list(val) for key, val in group_clean_doc_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранить обработанные данные на диск\n",
    "save_obj(group_clean_doc_dict, 'group_doc_dict_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение LDA модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import TextCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "class ListTextCorpus(TextCorpus):\n",
    "\n",
    "    def get_texts(self):\n",
    "        for doc in self.input:\n",
    "            yield doc\n",
    "                \n",
    "mycorp = ListTextCorpus(input=group_clean_doc_dict.values())\n",
    "justlda = LdaModel(\n",
    "    corpus=mycorp, num_topics=20, passes=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LdaModel performance\n",
      "0 идеянравиться скажетёс одинкто лучшенравиться подошван 10выбрать быкакать летомсупер летд однокто\n",
      "1 емес ішінд үшін болс барлық керека болада мена сияқт әрбір\n",
      "2 come time good night girl dream thing show peopl high\n",
      "3 естие такверный жевсё думаюэтый правдая согласнаэтый сказанополность понятьщас естьэтый словомконечный\n",
      "4 март человек друг ждать знать группа жизнь новое любимый писать\n",
      "5 масло ингредиент приготовление ложка соль добавлять рецепт сливочный сухой молоко\n",
      "6 чтoб ecть мoжнo кoгдa кaждый былo кoтopыe дeнь знaть мeнить\n",
      "7 кyзов 👍🏻ктo мaшинoть узнaeт новости😆 кpyчe кaтaлcть мaксимaльный becтe такoм\n",
      "8 кроликусачий штейнапроехидный кошкаориксычёрный тигрманулкаланкавказский песецбелый выдрамедновский цапляподковонос шлемоносныйрыся бурозубкакрасавкасиненосый цокорбеломордый\n",
      "9 більша якщый українить який україні рокіть зробить дуже такі цьий\n",
      "10 область россия центр город ребёнок тысяча человек общий улица право\n",
      "11 livingsorri испанииcountryside phothailand16siberian friendsin roadtripbi lovecattheboatthatrockedcat petshappi fx-3 woodsморской monkeyswat\n",
      "12 music love record hous night deep black live edit трек\n",
      "13 😍отличный заметкуумница❤мило😇хороший милоаудиотличный 😌спортяжечка💙круточёткогда-то ганкрасавецсочнокрута фитоняшка💖ого😍неплохо каефа стоит😏круто импалатомить 😇шикарный\n",
      "14 пьеса комедия актриса оскар борис режиссёр 1984 адам гений шедевр\n",
      "15 yдaeтcть peшeнue пpoвaлoм тeлeкaнaлa пpuнuмaeт xaoc плaнy гeнepaльнoгo cвou cepuaть\n",
      "16 любить твой жить жизнь понять пусть любовь счастие глаз сердце\n",
      "17 зaкaзaть jone дocтaвкa поздравляй👏🏻 женщин😃 кoрoбка пoдapка cкидкoть pадуть трycикoть\n",
      "18 дopoжe тепepь выгoд пocтaвлять зaкoнoмepный цeпoчкe пpoдaвaлcть teva cклepoзoм пocpeдникoть\n",
      "19 диск передний запчасть задний бампер кузов пробег торг авто двигатель\n"
     ]
    }
   ],
   "source": [
    "print('LdaModel performance')\n",
    "for i in range(20):\n",
    "    terms = justlda.get_topic_terms(i)\n",
    "    print(i, ' '.join(map(lambda x: mycorp.dictionary.get(x[0]), terms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group distribution by the most relevant topic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10    0.38\n",
       "4     0.36\n",
       "16    0.13\n",
       "5     0.03\n",
       "12    0.02\n",
       "0     0.02\n",
       "19    0.01\n",
       "6     0.01\n",
       "9     0.01\n",
       "14    0.01\n",
       "1     0.00\n",
       "2     0.00\n",
       "3     0.00\n",
       "17    0.00\n",
       "11    0.00\n",
       "8     0.00\n",
       "15    0.00\n",
       "18    0.00\n",
       "7     0.00\n",
       "13    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_dict = {key: 0 for key in range(20)}\n",
    "\n",
    "group_topics_dict_20 = {\n",
    "    group_id: dict(list(dummy_dict.items()) + justlda.get_document_topics(mycorp.dictionary.doc2bow(text)))\n",
    "    for group_id, text in group_clean_doc_dict.items()\n",
    "}\n",
    "check_pd_20 = pd.DataFrame.from_dict(group_topics_dict_20, orient='index')\n",
    "check_pd_20.head(10)\n",
    "print(\"Group distribution by the most relevant topic\")\n",
    "pd.Series.round(check_pd_20.idxmax(axis=1).value_counts() * 1. / len(check_pd_20), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump lda model to disk\n",
    "justlda.save('ldamodel_20_topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most typical groups for every topic\n",
      "0 идеянравиться скажетёс одинкто лучшенравиться подошван 10выбрать быкакать летомсупер летд однокто\n",
      "FASHION  мода http://vk.com/club33404310\n",
      "UN-ART| БОТ http://vk.com/club26141224\n",
      "BERLIN TECHNO GUIDE / berghain etc / http://vk.com/club10423\n",
      "Психоделический Мох http://vk.com/club179502424\n",
      "Наливные духи Reni http://vk.com/club169059498\n",
      "СЕКС В САРАТОВЕ! БЕСПЛАТНО) СЕКС ЗНАКОМСТВА! http://vk.com/club60714577\n",
      "Добавь в друзья http://vk.com/club24608732\n",
      "ПСД (Превосходные Славянские Девушки) Фото/видео http://vk.com/club58690425\n",
      "СМС приколы http://vk.com/club25554967\n",
      "Куплю, продам. Рязань и область. http://vk.com/club36487\n",
      "\n",
      "1 емес ішінд үшін болс барлық керека болада мена сияқт әрбір\n",
      "Родной. http://vk.com/club93753389\n",
      "Шын Жүректен | Казахстан http://vk.com/club67310453\n",
      "Сені сүйемін ♕ http://vk.com/club58960952\n",
      "Әлем тарихы http://vk.com/club60569162\n",
      "👉 ҚЫЗЫҚТЫ ОҚИҒАЛАР! 👈 http://vk.com/club132801212\n",
      "LET'S GET http://vk.com/club120573263\n",
      "Сушки на каждый день http://vk.com/club179084958\n",
      "Суқұйғыш http://vk.com/club93979344\n",
      "БОРЩ http://vk.com/club460389\n",
      "Признавашки Шиели👑 http://vk.com/club73478565\n",
      "\n",
      "2 come time good night girl dream thing show peopl high\n",
      "БПАН http://vk.com/club23741502\n",
      "Английский язык 🇬🇧 http://vk.com/club64980863\n",
      "Курсы английского языка Advance http://vk.com/club153397968\n",
      "BelleHome - интернет-журнал о дизайне интерьера http://vk.com/club29698527\n",
      "SobakinFX http://vk.com/club158780585\n",
      "NBA. Новости http://vk.com/club28402905\n",
      "Men's Bro | Мужское братство http://vk.com/club48030915\n",
      "ARCHVIS http://vk.com/club111328376\n",
      "Джазовый архивариус/Jazz Calendar/Джаз-календарь http://vk.com/club43416763\n",
      "Stars Facts http://vk.com/club40759514\n",
      "\n",
      "3 естие такверный жевсё думаюэтый правдая согласнаэтый сказанополность понятьщас естьэтый словомконечный\n",
      "Не для того мама ягодку растила! http://vk.com/club32494444\n",
      "Корпорация Юмора ツ http://vk.com/club23537466\n",
      "Knochenwald 4909 http://vk.com/club25654320\n",
      "Дорожные Войны http://vk.com/club153344099\n",
      "Приколы |  :D http://vk.com/club56325271\n",
      "Убойные приколы http://vk.com/club141623877\n",
      "Новинки Музыки 2019 http://vk.com/club23180464\n",
      "Фотографии http://vk.com/club23044992\n",
      "анекдотов.net http://vk.com/club22222333\n",
      "CRAZY DOCTOR | GIF http://vk.com/club149457043\n",
      "\n",
      "4 март человек друг ждать знать группа жизнь новое любимый писать\n",
      "Киномакс http://vk.com/club34767424\n",
      "Навка Шоу http://vk.com/club147841068\n",
      "Аватария Mobile — 101XP.com. Официальная группа. http://vk.com/club99897090\n",
      "Party Time | Дни Рождения | Праздники – СПб http://vk.com/club175189090\n",
      "Дельфин  Dolphin http://vk.com/club23402051\n",
      "Сра4ТВ | Sra4TV http://vk.com/club110429327\n",
      "ФК «Спартак-Москва» http://vk.com/club15502770\n",
      "Конкурсы Розыгрыши Призы бесплатно. Москва http://vk.com/club105253372\n",
      "Волейбол в Пензе | Подписывайся http://vk.com/club72591834\n",
      "Отдам даром http://vk.com/club127760598\n",
      "\n",
      "5 масло ингредиент приготовление ложка соль добавлять рецепт сливочный сухой молоко\n",
      "Райская кухня http://vk.com/club127719923\n",
      "КУХНЯ http://vk.com/club166012005\n",
      "Рецепты ПП: правильное питание, диетические http://vk.com/club72350250\n",
      "Вегетарианские рецепты http://vk.com/club35838585\n",
      "Энциклопедия хозяйки|Рецепты.Кулинарные хитрости http://vk.com/club60971453\n",
      "Кулинарное искусство http://vk.com/club47118092\n",
      "Рецепты правильного питания http://vk.com/club94098607\n",
      "Вкуснятина - пальчики оближешь! http://vk.com/club154615561\n",
      "Cook Good - лучшие рецепты http://vk.com/club39009769\n",
      "КУЛИНАРНЫЙ БЛОГ http://vk.com/club164041592\n",
      "\n",
      "6 чтoб ecть мoжнo кoгдa кaждый былo кoтopыe дeнь знaть мeнить\n",
      "Гречневая Кафка http://vk.com/club69864801\n",
      "ЯЖЛЕДИ! http://vk.com/club24260227\n",
      "Hi-Tech | Наука | Технологии http://vk.com/club142651399\n",
      "❤ Семья+Я ❤ http://vk.com/club130518487\n",
      "Первый Исторический http://vk.com/club159423374\n",
      "Видео http://vk.com/club26090596\n",
      "Животные http://vk.com/club44053675\n",
      "Стихи http://vk.com/club49573982\n",
      "Не болею | Рецепты здоровья и долголетия http://vk.com/club165313378\n",
      "Между нами, девочками ♥ http://vk.com/club101517329\n",
      "\n",
      "7 кyзов 👍🏻ктo мaшинoть узнaeт новости😆 кpyчe кaтaлcть мaксимaльный becтe такoм\n",
      "АВТОМИР http://vk.com/club86119599\n",
      "Пошлые http://vk.com/club27794994\n",
      "ШКОЛА СМЕХА ツ http://vk.com/club66523083\n",
      "• iFace http://vk.com/club30277672\n",
      "Воробушек http://vk.com/club147997399\n",
      "На Случай Важных Переговоров http://vk.com/club2661911\n",
      "Наливные духи Reni http://vk.com/club169059498\n",
      "Беспроводные наушники | г. Москва http://vk.com/club174918136\n",
      "Циник http://vk.com/club26090632\n",
      "Отфотошопим http://vk.com/club172644725\n",
      "\n",
      "8 кроликусачий штейнапроехидный кошкаориксычёрный тигрманулкаланкавказский песецбелый выдрамедновский цапляподковонос шлемоносныйрыся бурозубкакрасавкасиненосый цокорбеломордый\n",
      "Красная книга http://vk.com/club99084459\n",
      "- ADV CLUB | Авто, Мото, Тюнинг http://vk.com/club9494209\n",
      "ПОЗИТИВ ツ http://vk.com/club11614\n",
      "[Клуб Внедорожников Нива|Niva|L200|Hilux 4X4]™ http://vk.com/club49442228\n",
      "Психоделический Мох http://vk.com/club179502424\n",
      "АНЕКДОТЫ http://vk.com/club15797699\n",
      "Убойные приколы http://vk.com/club141623877\n",
      "Новинки Музыки 2019 http://vk.com/club23180464\n",
      "Фотографии http://vk.com/club23044992\n",
      "анекдотов.net http://vk.com/club22222333\n",
      "\n",
      "9 більша якщый українить який україні рокіть зробить дуже такі цьий\n",
      "Ukraїner http://vk.com/club5164516\n",
      "Логово Мужика http://vk.com/club156569037\n",
      "Канал 1+1 http://vk.com/club6970317\n",
      "Der Audi des letzten Jahrhunderts (1909 - 1999) http://vk.com/club94106068\n",
      "ТСН http://vk.com/club20035339\n",
      "УНИАН | УНІАН http://vk.com/club24187484\n",
      "Типичный Киев http://vk.com/club32195333\n",
      "VK Україна http://vk.com/club550910\n",
      "Театр кіно - Люм'єр http://vk.com/club7388912\n",
      "Історія та сучасність | Україна i свiт http://vk.com/club63807054\n",
      "\n",
      "10 область россия центр город ребёнок тысяча человек общий улица право\n",
      "Легион http://vk.com/club127229719\n",
      "Газета «СПЕЦНАЗ РОССИИ» и журнал «РАЗВЕДЧИКЪ» http://vk.com/club48144384\n",
      "События Улан-Удэ http://vk.com/club107493817\n",
      "БУРЯТИЯ ОНЛАЙН http://vk.com/club31683382\n",
      "Ассоциация организаций по защите семьи http://vk.com/club153414518\n",
      "Сатира Без Позитива / Новости с овощебазы http://vk.com/club19334776\n",
      "Правительство Ростовской области http://vk.com/club37680642\n",
      "NHK - Типичная Находка http://vk.com/club50109163\n",
      "Мурманская область http://vk.com/club120229555\n",
      "New - Сызрань http://vk.com/club28352059\n",
      "\n",
      "11 livingsorri испанииcountryside phothailand16siberian friendsin roadtripbi lovecattheboatthatrockedcat petshappi fx-3 woodsморской monkeyswat\n",
      "somewhere only we know || zissou's http://vk.com/club7235669\n",
      "MDK http://vk.com/club23148107\n",
      "Katerina Ermolaeva http://vk.com/club120019837\n",
      "Autoservice im Krüger http://vk.com/club155158524\n",
      "Малгобекер молодежь http://vk.com/club77413355\n",
      "НОВИНКИ МУЗЫКИ 2018 | Music http://vk.com/club18796946\n",
      "Психоделический Мох http://vk.com/club179502424\n",
      "DOGGOS http://vk.com/club102245159\n",
      "ПСД (Превосходные Славянские Девушки) Фото/видео http://vk.com/club58690425\n",
      "PULSAR http://vk.com/club9563604\n",
      "\n",
      "12 music love record hous night deep black live edit трек\n",
      "YooDj's http://vk.com/club44426090\n",
      "MGMT http://vk.com/club42394685\n",
      "Be happy and listen to... http://vk.com/club40780353\n",
      "Tiesto http://vk.com/club42645487\n",
      "Ed Sheeran http://vk.com/club137518957\n",
      "Armin van Buuren http://vk.com/club42743690\n",
      "yourtracklist http://vk.com/club86451899\n",
      "Чёрно-белая фотография http://vk.com/club29937606\n",
      "GLÜCKSЄLIGKEIT http://vk.com/club88284562\n",
      "Hardwell http://vk.com/club56074769\n",
      "\n",
      "13 😍отличный заметкуумница❤мило😇хороший милоаудиотличный 😌спортяжечка💙круточёткогда-то ганкрасавецсочнокрута фитоняшка💖ого😍неплохо каефа стоит😏круто импалатомить 😇шикарный\n",
      "† WoW † | Мужской рай http://vk.com/club64717635\n",
      "Уголок идиота http://vk.com/club36750744\n",
      "Distortion Bot http://vk.com/club142206444\n",
      "Психоделический Мох http://vk.com/club179502424\n",
      "Наливные духи Reni http://vk.com/club169059498\n",
      "PULSAR http://vk.com/club9563604\n",
      "ПСД (Превосходные Славянские Девушки) Фото/видео http://vk.com/club58690425\n",
      "Добавь в друзья http://vk.com/club24608732\n",
      "Куплю, продам. Рязань и область. http://vk.com/club36487\n",
      "СМС приколы http://vk.com/club25554967\n",
      "\n",
      "14 пьеса комедия актриса оскар борис режиссёр 1984 адам гений шедевр\n",
      "История: Россия и мир http://vk.com/club130360681\n",
      "Обман зрения http://vk.com/club86131661\n",
      "Новинки кино http://vk.com/club56176916\n",
      "Новости кино http://vk.com/club70389915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "КАМЕДИ БОТ | Comedy Club | КВН | Приколы | Юмор http://vk.com/club24373626\n",
      "Четкие Приколы http://vk.com/club23064236\n",
      "киноинфо http://vk.com/club34014795\n",
      "#Для тебя 💙 http://vk.com/club84289264\n",
      "Русские / Российские сериалы и фильмы http://vk.com/club42897151\n",
      "кусочек фильма http://vk.com/club70493648\n",
      "\n",
      "15 yдaeтcть peшeнue пpoвaлoм тeлeкaнaлa пpuнuмaeт xaoc плaнy гeнepaльнoгo cвou cepuaть\n",
      "HD Кино - Фильмы онлайн 2019 http://vk.com/club123915905\n",
      "НОВИНКИ КИНО 2019 http://vk.com/club90253744\n",
      "Алихакерша http://vk.com/club130271299\n",
      "HD Фильмы | Новинки кино 2019 http://vk.com/club52548908\n",
      "Я ❤ КИНО http://vk.com/club113071474\n",
      "ФИЛЬМЫ | КИНО 2019 http://vk.com/club41436884\n",
      "Книги http://vk.com/club44054326\n",
      "Видео http://vk.com/club26090596\n",
      "Стихи http://vk.com/club49573982\n",
      "КиноКайф - Лучшие фильмы http://vk.com/club58170807\n",
      "\n",
      "16 любить твой жить жизнь понять пусть любовь счастие глаз сердце\n",
      "Литературный кайф http://vk.com/club90983046\n",
      "О счастье-просто http://vk.com/club93028666\n",
      "Remember me http://vk.com/club41611636\n",
      "♥ Внешность - на время, Душа - навсегда ♥ http://vk.com/club26179938\n",
      "Женский гороскоп для Близнецов http://vk.com/club165974166\n",
      "Факты о родившихся 7 ноября http://vk.com/club128575637\n",
      "Трудный Возраст http://vk.com/club32535747\n",
      "Мотивация. Дальше - Больше! http://vk.com/club30179770\n",
      "Скромно. http://vk.com/club53570355\n",
      "I LOVE MOTO http://vk.com/club38221212\n",
      "\n",
      "17 зaкaзaть jone дocтaвкa поздравляй👏🏻 женщин😃 кoрoбка пoдapка cкидкoть pадуть трycикoть\n",
      "ЧП|Шокирующие Инциденты GIF http://vk.com/club150440233\n",
      "Music of Studio Ghibli http://vk.com/club71345821\n",
      "Cruel Gaga http://vk.com/club177766524\n",
      "Мужской рай http://vk.com/club38290762\n",
      "Комната Смеха http://vk.com/club111359826\n",
      "Корпорация Смеха http://vk.com/club25161110\n",
      "Академия Порядочных Парней http://vk.com/club45595714\n",
      "Институт Злых Гениев http://vk.com/club36614147\n",
      "Психоделический Мох http://vk.com/club179502424\n",
      "Циник http://vk.com/club26090632\n",
      "\n",
      "18 дopoжe тепepь выгoд пocтaвлять зaкoнoмepный цeпoчкe пpoдaвaлcть teva cклepoзoм пocpeдникoть\n",
      "Безумные приколы http://vk.com/club138880351\n",
      "Типичная Испания http://vk.com/club36164974\n",
      "Call Prank | БОТ http://vk.com/club149090176\n",
      "Новинки Музыки 2019 http://vk.com/club54500021\n",
      "Мир Знаний http://vk.com/club63268074\n",
      "Горячие ФАКТЫ http://vk.com/club45688121\n",
      "Психоделический Мох http://vk.com/club179502424\n",
      "РАДИ СМЕХА  ツ http://vk.com/club23333566\n",
      "sfadsfadfasfasf http://vk.com/club23834179\n",
      "Смешные анекдоты http://vk.com/club23863253\n",
      "\n",
      "19 диск передний запчасть задний бампер кузов пробег торг авто двигатель\n",
      "Авторазбор Автовыкуп  в Магнитогорске http://vk.com/club145985340\n",
      "Kolesa K12 http://vk.com/club76368500\n",
      "Курык хабарландыру тактасы!!! http://vk.com/club75480326\n",
      "Japan club | Toyota Nissan Honda Subaru Mazda http://vk.com/club48036055\n",
      "Wornpath http://vk.com/club48006306\n",
      "Чёткие приколы http://vk.com/club31836774\n",
      "Территория уюта http://vk.com/club161056503\n",
      "MAZDA БАРАХОЛКА ЗАПЧАСТИ МАЗДА http://vk.com/club65090713\n",
      "АВТОБАРАХОЛКА САРАНСК http://vk.com/club61161094\n",
      "Авто-Мото Тверь http://vk.com/club118602458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The most typical groups for every topic\")\n",
    "for i in range(20):\n",
    "    terms = justlda.get_topic_terms(i)\n",
    "    print(i, ' '.join(map(lambda x: mycorp.dictionary.get(x[0]), terms)))\n",
    "    typical_groups = check_pd_20[i].sort_values(ascending=False).index[:10]\n",
    "    for g in typical_groups:\n",
    "        group_info = vk_get_response(\n",
    "            'groups.getById', 'group_ids={0}&v=4.9&lang=ru'.format(g), access_token\n",
    "        )\n",
    "        print(group_info['response'][0]['name'] + ' ' + 'http://vk.com/club' + str(g))\n",
    "        time.sleep(0.3)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Продолжение следует"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
